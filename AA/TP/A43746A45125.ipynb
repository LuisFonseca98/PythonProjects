{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img src=\"http://gi-mosm.dem.isel.pt/compdrill/img/logo_isel.png\" style=\"width:300px; float: right; margin: 0 40px 40px 40px;\"></img>\n",
    "\n",
    "### Instituto Superior de Engenharia de Lisboa\n",
    "### Licenciatura Em Informática e Multimética\n",
    "# Aprendizagem Automática\n",
    "\n",
    "## TRABALHO PRÁTICO \n",
    "\n",
    "Trabalho realizado por:\n",
    "    \n",
    "* Gonçalo Almeida - 43746\n",
    "* Luís Fonseca    - 45125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "## Indice\n",
    "-> [Introdução](#introducao)<br/>\n",
    "-> [Classificadores Escolhidos](#classificadores)<br/>\n",
    "-> [Vetorização do Texto](#vetores)<br/>\n",
    "-> [Classificação Binária](#binario)<br/>\n",
    "-> [Classificação Multiclass](#multiclass)<br/>\n",
    "-> [Regressão Linear](#linear)<br/>\n",
    "-> [Dimensão do Dicionário](#dimensao)<br/>\n",
    "-> [Conclusões](#conclusao)<br/>\n",
    "-> [Bibliografia](#bibliografia)<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "## Introdução<a name=\"introducao\"/>\n",
    "\n",
    "O trabalho prático de Aprendizagem Automática consiste na aplicação de diferentes classificadores, e escolher, qual obtém uma melhor classificação. Para testarmos os diferentes classificadores, usamos o ficheiro fornecido pelo docente responsável da disciplina. Esse ficheiro, de nome \"IMDBcríticas\" consiste em 40000 diferentes críticas, irá ser usado para testar os classificadores aqui escolhidos. É de notar que, visto que estamos a trabalhar com um grande conjunto de dados, muitos dos classificadores aqui usados, apresentam um tempo de processamento excessivo, portanto apenas iremos testar com uma pequena parte dos dados, assim como, usar a maior parte dos parâmetros que foram testados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "## Classificadores Escolhidos<a name=\"classificadores\"/>\n",
    "\n",
    "Visto que foi a realização do projeto foi em grupo, foram escolhidos três classificadores, e mais outros dois tópicos opcionais. Os classificadores aqui usados foram os seguintes:\n",
    "\n",
    "* RegressãoLogística(ou LogisticRegression): usado para modelar a probabilidade de uma determinada classe ou evento existir, como aprovação/reprovação, vitória/derrota, vivo/morto. \n",
    "* Máquina de Suporte Vetorial(Suport Vetorial Machine or SVM): é um modelo de aprendizagem supervisionada com algoritmos de aprendizagem associados que analisam dados para classificação e análise de regressão.\n",
    "* KNN: usado para classificação e regressão. Em ambos os casos, a entrada consiste nos k exemplos de treinamento mais próximos no conjunto de dados. A saída depende se k-NN é usado para classificação ou regressão. Na regressão k-NN, a saída é o valor da propriedade do objeto.\n",
    "\n",
    "E os tópicos opcionais escolhidos foram os seguintes:\n",
    "\n",
    "* Regressão Linear: abordagem linear para modelar a relação entre uma resposta escalar e uma ou mais variáveis explicativas (também conhecidas como variáveis dependentes e independentes).\n",
    "\n",
    "\n",
    "* Dimensão do Vocabulário: investigar a influência do tamanho do dicionário(dimensão dos dados) no desempenho de um discriminante logístico no problema de classificação binária.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "## Vetorização do Texto <a name=\"vetores\"/>\n",
    "Como primeiro passo, foi necessário dividir os dados de texto, em treino e de teste, para se possam realizar uma avaliação correta da quantidade de acertos de cada classificador. Como primeiro passo para a realização da vetorização, recorremos às bibliotecas da linguagem python, uma delas de nomede nome *`sklearn`* contendo os métodos necessários que permite fazer a respetiva conversão.\n",
    "\n",
    "Recorremos também à biblioteca *`nltk`* para aplicar *`stemming`*, durante a realização, testamos todos os tipos de stemmers, sendo que foi usado o *`PorterStemmer`* com mais frequência.\n",
    "\n",
    "Como último método, usamos o método *`train_test_split`* que permite efetuar a divisão dos dados em treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pickle\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos também a biblioteca *`pickle`* que permite abrir ficheiros dentro do formato pickle, e guardar o mesmo ficheiro, aplicando limpeza e o stemming usado. A seguir podemos ver a biblioteca *`pickle`* a ser usada, para abrir o ficheiro que foi fornecido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=pickle.load(open('imdbCriticas.p','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o ficheiro aberto, procedemos à limpeza do ficheiro. Para isso foi criado o método *`clear_test(original_data)`* que ao ser passado o ficheiro como argumento da função, permite eliminar mudanças de linhas dentro do ficheiro, e substituir tudo que não seja caracteres alfabéticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Método que recebe um documento, fazendo a sua limpeza\"\"\"\n",
    "def clear_text(original_data):\n",
    "    \n",
    "    print(\"Start text clearing\")\n",
    "    data = [doc.replace('<br />',' ') for doc in original_data] # substituir as mudanças de linha\n",
    "    data2 = [re.sub(r'[^a-zA-Z]+', ' ',doc)for doc in data] # tirar tudo que não é caracteres alfabeticos fora\n",
    "    print(\"Text clearing finished\")\n",
    "    return data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De seguida, criamos o método *`stemming(original_data,stemType=\"Porter\", language = \"english\")`* que permite aplicar stemming, depois de ter sido feito a limpeza do ficheiro. Para este método, passamos os três tipos de stemers que existem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Aplica os 3 tipos de stemming ao documento recebido\"\"\"\n",
    "def stemming(original_data,stemType=\"Porter\", language = \"english\"):\n",
    "    \n",
    "    stemmers = {\"porter\": PorterStemmer(),\n",
    "            \"snowball\": SnowballStemmer(\"english\"),\n",
    "            \"lancaster\": LancasterStemmer()}\n",
    "    stemmer = stemmers[stemType.lower()]\n",
    "    print(\"Start stemming: \",stemType,\"Stemmer\\n\")\n",
    "    stemmed_data = [\" \".join([stemmer.stem(word) for word in text.split()]) for text in original_data]\n",
    "    print(\"Stemming finished.\\n\")\n",
    "    return stemmed_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o stemming aplicado, e a limpeza feita, criamos o método *`save_text(Data,Target.stemType)`* que permite guardar um novo ficheiro, depois das alterações feitos. Dentro deste ficheiro, guardamos os novos dados (*`Data`*), assim como o *`Target`*. No final usamos o método *`dump`* da biblioteca *`pickle`* para guardar o novo ficheiros, com os dados mais recentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Método que guarda o texto, depois de ter feito uma limpeza\"\"\"\n",
    "def save_text(Data,Target,stemType):\n",
    "    \n",
    "    D = {'data' : Data,'target' : Target}\n",
    "    print(\"Writing data.\")\n",
    "    pickle.dump(D, open('imdbFull' + str(stemType) + '.p', 'wb')) \n",
    "    print(\"Data written successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi também criado o método *`save_data(data,name)`* que permite guardar os classificadores num ficheiro, após ter sido aplicado o método fit, utilizando os dados de treino, sobre os mesmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Método que permite guardar os novos dados\"\"\"\n",
    "def save_data(data,name):\n",
    "    \n",
    "    D = {'data' : data}\n",
    "    print(\"Writing data.\")\n",
    "    pickle.dump(D, open(str(name) + '.p', 'wb')) \n",
    "    print(\"Data written successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de passar para a divisão do texto para vetores, efetuamos um teste, comprovando o correto funcionamento dos métodos criados anteriormente, passando o tipo de stemming com sendo \"Porter\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start text clearing\n",
      "Text clearing finished\n",
      "Start stemming:  Porter Stemmer\n",
      "\n",
      "Stemming finished.\n",
      "\n",
      "Writing data.\n",
      "Data written successfully\n"
     ]
    }
   ],
   "source": [
    "D=pickle.load(open('imdbCriticas.p','rb'))\n",
    "Data=D['data']\n",
    "Target=D['target']\n",
    "stemType = \"Porter\"\n",
    "clean_data = clear_text(Data)\n",
    "stemmed_data = stemming(clean_data,stemType)\n",
    "save_text(stemmed_data, Target, stemType)\n",
    "#x_train, x_test, y1, y2 = train_test_split(Data, Target)\n",
    "#x_train2, x_test2, voc2 = textoSplitTreinoTeste(Data[:50],Data[50:150], n_grams = (1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois de ter sido guardado o novo ficheiro, procedemos à realização da divisão do ficheiro, em treino e teste. Para isso foi criado o método *`text_to_vetor(Xtrain,Xtest,ytrain, ytest, min_doc_freq = 5, language = 'english',n_grams = (1,3))`*, recebendo como argumentos os dados de treino e de teste, um min_doc_freq igual a 5, verificando apenas 50% dos documentos, e passando n-gramas, de (1,3).\n",
    "\n",
    "Recorremos ao método *`TfidfVectorizer`* para aplicar esse conjunto de dados, numa matriz tfidf, passando os n-gramas e a quantidade mínima (*`min_df`*) \n",
    "\n",
    "No final, aplicamos esta transformação, tantos para os dados de treino, como para os dados de teste. No final, retornamos os dados de teste e de treino convertidos, assim como um vocabulário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Método que converte o texto numa matriz(X) \"\"\"\n",
    "def text_to_vector(Xtrain,Xtest,ytrain, ytest, min_doc_freq = 5, language = 'english',n_grams = (1,3)):\n",
    "    \n",
    "    print(\"Converting text into vectors.\")\n",
    "    pattern = r'\\b\\w\\w\\w\\w+\\b' if n_grams == (1,1) else r'\\b\\w\\w+\\b'\n",
    "    tfidf = TfidfVectorizer(min_df = min_doc_freq, token_pattern = pattern, ngram_range = n_grams, stop_words = language)\n",
    "    tfidf.fit(Xtrain)\n",
    "    save_data(tfidf,\"tfidf_treinado\")\n",
    "    voc = tfidf.get_feature_names()\n",
    "    \n",
    "    #Projecção dos vectores\n",
    "    x_train = tfidf.transform(Xtrain)\n",
    "    x_test = tfidf.transform(Xtest)\n",
    "    print(\"Finished conversion.\")\n",
    "    return x_train, x_test, ytrain, ytest, voc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método acima descrito é apenas utilizado para efeitos de teste, sendo ainda necessário criar o método *`text2vector`*.\n",
    "\n",
    "Este método recebe um dicionário composto por Data e Target. De modo a obter estes valores é evocado o método *`unpack`*, sendo, seguidamente, realizada a limpeza do texto e o stemming do texto limpo.\n",
    "\n",
    "Por fim vai-se obter o tf-idf previamente treinado e, aplicando o mesmo, é realizada a vetorização destes dados, sendo, por fim, os mesmos guardados novamente num dicionário.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Método que permite correr a vetorização por texto\"\"\"\n",
    "def text2vector(Docs):\n",
    "    \n",
    "    Data, Target = unpack(Docs)\n",
    "    clean_data = clear_text(Data)\n",
    "    stemmed_data = stemming(clean_data,\"Porter\")\n",
    "    \n",
    "    fName=\"tfidf_treinado.p\"\n",
    "    D = pickle.load(open(fName, 'rb'))\n",
    "    tfidf = D['data']\n",
    "    \n",
    "    vector_data = tfidf.transform(stemmed_data)\n",
    "    X = {'data':vector_data, 'target':Target}\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting text into vectors.\n",
      "Writing data.\n",
      "Data written successfully\n",
      "Finished conversion.\n"
     ]
    }
   ],
   "source": [
    "D=pickle.load(open('imdbFullPorter.p','rb'))\n",
    "Data=D['data']\n",
    "Target=D['target']\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(Data, Target, test_size=0.3, random_state=42)\n",
    "Xtrain2, Xtest2, ytrain, ytest , voc2 = text_to_vector(Xtrain, Xtest, ytrain, ytest, n_grams = (1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "O método *`unpack`* foi criado de modo a simplificar o código e de modo a evitar a repetição de código. Este método apenas recebe um dicionário com Data e Target e retorna estes valores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Método que retorna as keys existentes no ficheiro\"\"\"\n",
    "def unpack(X):\n",
    "    \n",
    "    x=X['data']\n",
    "    y=X['target']\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "## Classificador Binário <a name=\"binario\"/>\n",
    "\n",
    "Após termos efetuado a vetorização do texto, passamos para a classificação, em binária, dos dados usados. Escolhidos três tipos de classificadores, elaboramos um método para cada classificador, para ficar a saber qual aquele que apresenta melhores resultados.\n",
    "\n",
    "Como primeiro passo, iremos importar as bibliotecas necessárias, e os seus métodos que cada biblioteca contém.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro classificador que decidimos estudar foi o *`logistic regression`*. Para isso criamos o método *`logistic_regression(Xtrain,Xtest,y1,y2, penaltyType = 'l1',cValue = None, solverType = 'liblinear', save_string=\"lr\")`* que recebe como argumentos os dados de treino e teste, ambos dividos pela vetorização, e passado como argumento o tipo de penalização que este classificador recebe(neste caso o lasso, ou seja 'l1', podendo ser alterado para ridge, ou seja 'l2'), o valor do coeficiente de correlação (neste caso ficou a None, visto que foi necessário para obter o melhor parâmetro), e o tipo de solver(que neste caso, obtamos por deixar como sendo 'liblinear').\n",
    "\n",
    "Para verificar qual o melhor parâmetro, criamos a condição *`if cValue is None`*. Caso esta condição seja verdadeira, verificamos o tipo de penalização para este classificador:\n",
    "\n",
    "* Caso o tipo de penalização seja lasso, ou seja, 'l1', criamos um dicionário de nome *`parametros`*, onde contém os diferentes valores do coeficiente de correlação, e os diferentes tipos de solvers que serão usados, e no final usamos o método *`logistic regression`* para aplicar consoante estes valores.\n",
    "* Caso o tipo de penalização seja ridge, ou seja, 'l2', criamos um dicionário de nome *`parametros`*, onde contém os diferentes valores do coeficiente de correlação, e os diferentes tipos de solvers que serão usados, e no final usamos o método *`logistic regression`* para aplicar consoante estes valores.\n",
    "* Ainda dentro da condição, caso não seja escolhido um valor do coeficiente de correlação, usamos o método *`GridSearchCV`* que permite obter o melhor parâmetro, passando este tipo de classificador.\n",
    "\n",
    "Caso a condição não seja verdadeira, aplicamos o método *`logistic regression`* consoante os valores que passamos nos argumentos no início deste método.\n",
    "\n",
    "No final é calculado o valor do score, tanto do treino como do teste, obtendo diferentes resultados, e tirar conclusões de qual o melhor solver e o melhor parâmetro a ser usado. Também optamos por imprimir a matriz de confusão, vendo quantos tipos de verdadeiros/falsos positivos/negativos podiamos obter. E no final, para testar que estamos a usar este classificador como sendo binário, imprimimos a matriz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Método que calcula regressão logística, consoante o tipo de penalização(lasso - l1 ou ridge - l2)\n",
    "e os diferentes tipos de solvers que existem\n",
    "\"\"\"\n",
    "def logistic_regression(Xtrain,Xtest,y1,y2, penaltyType = 'l1',cValue = None, solverType = 'liblinear',\n",
    "                        save_string=\"lr\"):\n",
    "    \n",
    "    gs = None\n",
    "    tipoRegressao = \"Lasso\" if penaltyType == \"l1\" else \"Ridge\\n\" \n",
    "    gs_best_parameter = None\n",
    "    print(\"Initializing logistic regression \",\"Lasso\" if penaltyType == \"l1\" else \"Ridge\\n\")\n",
    "    if cValue is None:\n",
    "        if penaltyType == \"l1\":\n",
    "            parametros = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                          'solver':('liblinear','saga')\n",
    "                          }\n",
    "            lr = LogisticRegression(penalty=penaltyType,C= cValue,solver = solverType,max_iter=5000)\n",
    "        elif penaltyType == \"l2\":\n",
    "            parametros={'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                        'solver' : ('saga','sag', 'lbfgs', 'newton-cg')\n",
    "                        }\n",
    "            lr = LogisticRegression(penalty = penaltyType,C= cValue,solver = solverType,max_iter = 5000)\n",
    "        gs = GridSearchCV(lr, parametros)\n",
    "        gs.fit(Xtrain,y1)\n",
    "        gs_best_parameter = gs.best_params_\n",
    "        print(\"Best parameter: \", str(gs_best_parameter))\n",
    "    else:\n",
    "        gs = LogisticRegression(penalty = penaltyType, solver = solverType, C = cValue, max_iter = 5000)\n",
    "        gs.fit(Xtrain,y1)\n",
    "        \n",
    "    save_data(gs,save_string) \n",
    "    print(\"----\", gs)\n",
    "    scoreTrain = np.round(gs.score(Xtrain, y1) * 100, 3)\n",
    "    scoreTest = np.round(gs.score(Xtest, y2) * 100, 3)\n",
    "    \n",
    "    print(\"Train success: \" + str(np.round(gs.score(Xtrain, y1) * 100, 3)))\n",
    "    print(\"Test success: \" + str(np.round(gs.score(Xtest, y2) * 100, 3)))\n",
    "    y2n = gs.predict(Xtest)\n",
    "    print(\"Confusion matrix: \\n\" + str(confusion_matrix(y2, y2n)))\n",
    "    print(\"Test Classes: \" + str(gs.predict(Xtest)))\n",
    "    print(\"Logistic regression \",\"Lasso\" if penaltyType == \"l1\" else \"Ridge\",  \"Finished \")\n",
    "    \n",
    "    return scoreTrain,scoreTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary classification\n",
      "Inicialização de Regressão Logistica  Lasso\n",
      "Writing data.\n",
      "Data written successfully\n",
      "Train success: 100.0\n",
      "Test success: 88.725\n",
      "Confusion matrix: \n",
      "[[5417  725]\n",
      " [ 628 5230]]\n",
      "Test Classes: [0. 0. 0. ... 1. 0. 0.]\n",
      "Logistic regression  Lasso Finished \n",
      "Finished binary classification\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100.0, 88.725)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_classify(Xtrain2, Xtest2, ytrain, ytest,\n",
    "                classifier_type = 'logistic lasso', \n",
    "                cValue = 100,\n",
    "                solverType=\"saga\",\n",
    "                save_str=\"bin_lr_lasso_porter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary classification\n",
      "Initializing logistic regression  Ridge\n",
      "\n",
      "Writing data.\n",
      "Data written successfully\n",
      "---- LogisticRegression(C=10, max_iter=5000, solver='sag')\n",
      "Train success: 99.725\n",
      "Test success: 90.433\n",
      "Confusion matrix: \n",
      "[[5485  657]\n",
      " [ 491 5367]]\n",
      "Test Classes: [0. 1. 0. ... 1. 0. 1.]\n",
      "Logistic regression  Ridge Finished \n",
      "Finished binary classification\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(99.725, 90.433)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_classify(Xtrain2, Xtest2, ytrain, ytest,\n",
    "                classifier_type = 'logistic ridge', \n",
    "                cValue = 10,\n",
    "                solverType=\"sag\",\n",
    "                save_str=\"bin_lr_ridge_porter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10, max_iter=5000, solver='sag')\n",
      "Confusion matrix: \n",
      "[[   0    0    0    0    0    0    0    0    0]\n",
      " [2452  135    0    0    0    0    0    0    0]\n",
      " [1015   89    0    0    0    0    0    0    0]\n",
      " [1032  156    0    0    0    0    0    0    0]\n",
      " [ 986  277    0    0    0    0    0    0    0]\n",
      " [ 181  909    0    0    0    0    0    0    0]\n",
      " [ 127 1243    0    0    0    0    0    0    0]\n",
      " [  65  991    0    0    0    0    0    0    0]\n",
      " [ 118 2224    0    0    0    0    0    0    0]]\n",
      "nonzero y2n 6024\n",
      "nonzero y2 12000\n"
     ]
    }
   ],
   "source": [
    "D=pickle.load(open('bin_lr_ridge_porter.p','rb'))\n",
    "gs=D['data']\n",
    "print(gs)\n",
    "y2file=gs.predict(Xtest2)\n",
    "print(\"Confusion matrix: \\n\" + str(confusion_matrix(ytest, y2file)))\n",
    "print(\"nonzero y2n\",np.count_nonzero(y2file))\n",
    "print(\"nonzero y2\",np.count_nonzero(ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O segundo classificador que decidimos estudar foi o *`SVM, Máquina de Suporte Vetorial`*. Para isso criámos o método *`SVM(Xtrain, Xtest, y1, y2, cValue = None, kernelType = None, save_string=\"svm\")`* que recebe como argumentos os dados de treino e teste, ambos dividos pela vetorização, e passado como argumento o tipo de kernel que este classificador recebe o valor do coeficiente de correlação (neste caso ficou a None, visto que foi necessário para obter o melhor parâmetro).\n",
    "\n",
    "Para verificar qual o melhor parâmetro, criamos a condição *`if cValue is None and kernelType is None`*. Caso esta condição seja verdadeira, criamos um dicionário de nome *`parametros`*, onde contém os diferentes valores do coeficiente de correlação, e os diferentes tipos de kernels que serão usados, e no final usamos o método *`SVC`* para aplicar consoante estes valores. Ainda dentro da condição, caso não seja escolhido um valor do coeficiente de correlação, usamos o método *`GridSearchCV`* que permite obter o melhor parâmetro, passando este tipo de classificador.\n",
    "\n",
    "Caso a condição não seja verdadeira, aplicamos o método *`SVC`* consoante os valores que passamos nos argumentos no início deste método.\n",
    "\n",
    "No final é calculado o valor do score, tanto do treino como do teste, obtendo diferentes resultados, e tirar conclusões de qual o melhor solver e o melhor parâmetro a ser usado. Também optamos por imprimir a matriz de confusão, vendo quantos tipos de verdadeiros/falsos positivos/negativos podiamos obter. E no final, para testar que estamos a usar este classificador como sendo binário, imprimimos a matriz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Método que calcula o SVM(máquina de suporta vetorial), passando um tipo de kernel\"\"\"\n",
    "def SVM(Xtrain, Xtest, y1, y2, cValue = None, kernelType = None, save_string=\"svm\"):\n",
    "    \n",
    "    gs = None\n",
    "    print(\"Starting SVM\")\n",
    "    if cValue is None and kernelType is None:\n",
    "        parameters = {\n",
    "            'C': [0.001, 0.01, 0.1, 1, 10, 100], \n",
    "            'kernel' : ('linear', 'rbf', 'sigmoid')\n",
    "            }\n",
    "        svm = SVC(gamma = 'auto',max_iter=-1,decision_function_shape='ovr')\n",
    "        gs = GridSearchCV(svm, parameters)\n",
    "        gs.fit(Xtrain,y1)\n",
    "        print(\"Best parameter: \", str(gs.best_params_))\n",
    "    else:\n",
    "        gs = SVC(gamma='auto', max_iter= -1, decision_function_shape='ovr', C = cValue, kernel = kernelType)\n",
    "        gs.fit(Xtrain,y1)\n",
    "    \n",
    "    save_data(gs,save_string)\n",
    "    print(\"Train success: \" + str(np.round(gs.score(Xtrain, y1) * 100, 3)))\n",
    "    print(\"Test success: \" + str(np.round(gs.score(Xtest, y2) * 100, 3)))\n",
    "    y2n = gs.predict(Xtest)\n",
    "    print(\"Confusion matrix: \\n\" + str(confusion_matrix(y2, y2n)))\n",
    "    print(\"nonzero y2n\",np.count_nonzero(y2n))\n",
    "    print(\"nonzero y2\",np.count_nonzero(y2))\n",
    "    \n",
    "    # print(\"Test classes: \" + str(gs.predict(Xtest)))\n",
    "    print(\"SVM concluded\")\n",
    "    return np.round(gs.score(Xtrain, y1) * 100, 3), np.round(gs.score(Xtest, y2) * 100, 3) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary classification\n",
      "Starting SVM\n",
      "Writing data.\n",
      "Data written successfully\n",
      "Train success: 98.104\n",
      "Test success: 90.208\n",
      "Confusion matrix: \n",
      "[[5457  685]\n",
      " [ 490 5368]]\n",
      "nonzero y2n 6053\n",
      "nonzero y2 5858\n",
      "SVM concluded\n",
      "Finished binary classification\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(98.104, 90.208)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determinar melhor parametro para o SVM utilizando menos dados\n",
    "bin_classify(Xtrain2, Xtest2, ytrain, ytest,\n",
    "                classifier_type = 'svm', \n",
    "                cValue = 1, \n",
    "                kernelType = 'linear',\n",
    "                n_neighborsValue=None,\n",
    "                save_str='bin_svm_porter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O terceiro e último classificador que decidimos estudar foi o *`kNN`*. Para isso criamos o método *`kNN(Xtrain, Xtest, y1, y2, n_neighborsValue = 5, save_string='knn')`* que recebe como argumentos os dados de treino e teste, ambos dividos pela vetorização, e passado como argumento a quantidade de vizinhos, neste caso, para teste, optamos por deixar com 5 vizinhos.\n",
    "\n",
    "Para verificar qual o melhor parâmetro, criamos a condição *`if n_neighborsValue == None`*. Caso esta condição seja verdadeira, criamos um dicionário de nome *`parameters`*, onde contém os diferentes valores de vizinhança. De seguida, usamos o método *`KNeighborsClassifier()`*. Ainda dentro desta condição, para obter o melhor parâmetro(neste caso, para este classificador, o melhor valor de vizinhança) \n",
    "Caso a condição não seja verdadeira, aplicamos o método *`SVC`* consoante os valores que passamos nos argumentos no início deste método.Usamos o método *`GridSearchCV`* que permite obter o melhor parâmetro, passando este tipo de classificador.\n",
    "\n",
    "No final é calculado o valor do score, tanto do treino como do teste, obtendo diferentes resultados, e tirar conclusões de qual o melhor melhor vizinho a ser usado. Também optamos por imprimir a matriz de confusão, vendo quantos tipos de verdadeiros/falsos positivos/negativos podiamos obter. E no final, para testar que estamos a usar este classificador como sendo binário, imprimimos a matriz de teste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Método que calcula a vizinhança knn, passando como argumento o número de vizinhos\"\"\"\n",
    "def kNN(Xtrain, Xtest, y1, y2, n_neighborsValue = 5, save_string='knn'):\n",
    "    gs = None\n",
    "    print(\"kNN started.\")\n",
    "    if n_neighborsValue == None:\n",
    "        # Parametros a testar\n",
    "        parameters = {\n",
    "                'n_neighbors': [ 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, \n",
    "                                100, 105, 110, 115, 120, 125, 130, 135, 140, 145, 150, 155, 160, 165, 170, 175, 180, 185, 190, 195, \n",
    "                                200, 205, 210, 215, 220, 225, 230, 235, 240, 245, 250, 255, 260, 265, 270, 275, 280, 285, 290, 295, \n",
    "                                300, 305, 310, 315, 320, 325, 330, 335, 340, 345, 350, 355, 360, 365, 370, 375, 380, 385, 390, 395, \n",
    "                                400, 405, 410, 415, 420, 425, 430, 435, 440, 445, 450, 455, 460, 465, 470, 475, 480, 485, 490, 495] \n",
    "\n",
    "                }\n",
    "        knn = KNeighborsClassifier()\n",
    "        # GridSearch para obter os melhores parametros de classificação\n",
    "        gs = GridSearchCV(knn, parameters)\n",
    "        gs.fit(Xtrain, y1)\n",
    "        print(\"Melhor parametro: \" + str(gs.best_params_))\n",
    "    else:\n",
    "        gs = KNeighborsClassifier(n_neighbors = n_neighborsValue)\n",
    "        gs.fit(Xtrain, y1)\n",
    "    \n",
    "    save_data(gs,save_string)\n",
    "    print(\"Train success: \" + str(np.round(gs.score(Xtrain, y1) * 100, 3)))\n",
    "    print(\"Test success: \" + str(np.round(gs.score(Xtest, y2) * 100, 3)))\n",
    "    y2n = gs.predict(Xtest)\n",
    "    print(\"Confusion matrix: \\n\" + str(confusion_matrix(y2, y2n)))\n",
    "    print(\"Test classes: \" + str(gs.predict(Xtest)))\n",
    "    print(\"kNN Classifier concluded.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary classification\n",
      "kNN started.\n",
      "Writing data.\n",
      "Data written successfully\n",
      "Train success: 82.943\n",
      "Test success: 82.367\n",
      "Confusion matrix: \n",
      "[[5191  951]\n",
      " [1165 4693]]\n",
      "Test classes: [0. 0. 0. ... 1. 0. 1.]\n",
      "kNN Classifier concluded.\n",
      "Finished binary classification\n"
     ]
    }
   ],
   "source": [
    "bin_classify(Xtrain2, Xtest2, ytrain, ytest,\n",
    "                classifier_type = 'knn', \n",
    "                n_neighborsValue=200,\n",
    "                save_str='bin_knn_nn200_porter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary classification\n",
      "kNN started.\n",
      "Writing data.\n",
      "Data written successfully\n",
      "Train success: 82.893\n",
      "Test success: 82.475\n",
      "Confusion matrix: \n",
      "[[5269  873]\n",
      " [1230 4628]]\n",
      "Test classes: [0. 0. 0. ... 1. 0. 1.]\n",
      "kNN Classifier concluded.\n",
      "Finished binary classification\n"
     ]
    }
   ],
   "source": [
    "bin_classify(Xtrain2, Xtest2, ytrain, ytest,\n",
    "                classifier_type = 'knn', \n",
    "                n_neighborsValue=300,\n",
    "                save_str='bin_knn_nn300_porter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar a parte que diz respeito à classificação binária, foi realizado o método *`bin_classify(Xtrain,Xtest,y1,y2,classifier_type = 'logistic lasso', cValue = None, solverType = None, kernelType = None,n_neighborsValue=None,save_str=None)`*. Dentro deste método, fazemos a conversão dos dados para binário, através da seguinte condição:*` y1 = (y1 >= 7) * 1.0`* e *` y2 = (y2 >= 7) * 1.0`*. Para finalizar, criamos diferentes condições para verificar qual o tipo de classificador que queremos correr. Ao ser chamado este método, sempre que o tipo de classificador seja \"logistic lasso\", irá ser corrido o método que foi criado para a regressão logísica, neste caso, para o lasso. O procedimento para correr os outros classificadores é idêntico. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Método que retorna os resulados do treino e do teste, consoante a classificação (em binário) escolhida\"\"\"\n",
    "def bin_classify(Xtrain,Xtest,y1,y2,\n",
    "                classifier_type = 'logistic lasso', \n",
    "                cValue = None, \n",
    "                solverType = None, \n",
    "                kernelType = None,\n",
    "                n_neighborsValue=None,\n",
    "                save_str=None):\n",
    "    \n",
    "    y1 = (y1 >= 7) * 1.0\n",
    "    y2 = (y2 >= 7) * 1.0\n",
    "    print(\"Binary classification\")    \n",
    "    classifier_type = classifier_type.lower() # evitar erros de capitalização\n",
    "    resultado = 0\n",
    "    \n",
    "    if classifier_type == 'logistic lasso': result = logistic_regression(Xtrain, Xtest, y1, y2,'l1', cValue, solverType, save_str)\n",
    "    if classifier_type == 'logistic ridge': result = logistic_regression(Xtrain, Xtest, y1, y2,'l2', cValue, solverType, save_str)\n",
    "    if classifier_type == 'svm': result = SVM(Xtrain, Xtest, y1, y2,cValue,kernelType, save_str)\n",
    "    if classifier_type == 'knn': result = kNN(Xtrain, Xtest, y1, y2, n_neighborsValue, save_str)\n",
    "    print(\"Finished binary classification\")\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "O método *`binClassify`* recebe o dicionário com os dados vetorizados resultante da aplicação do método *`text2vector`*.\n",
    "Neste método é evocado o método *`unpack`* para obter os dados e as classes a que estes dados pertencem. Seguidamente é obtido o classificador binário previamente treinado que obteve melhores resultados, o SVM, e é realizado o *`predict`* sobre os dados que são fornecidos. Por fim é retornado um array com o resultado deste *`predict`*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Método que classifica o ficheiro passado em binário, com o melhor clasificador usado\"\"\"\n",
    "def binClassify(X):\n",
    "    x, y = unpack(X)\n",
    "    fName = \"bin_svm_porter.p\"\n",
    "    D = pickle.load(open(fName, 'rb'))\n",
    "    gs = D['data']\n",
    "    yBin = gs.predict(x)\n",
    "    return yBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start text clearing\n",
      "Text clearing finished\n",
      "Start stemming:  Porter Stemmer\n",
      "\n",
      "Stemming finished.\n",
      "\n",
      "Confusion matrix: \n",
      "[[19171  1039]\n",
      " [  731 19059]]\n"
     ]
    }
   ],
   "source": [
    "D=pickle.load(open('imdbFullPorter.p','rb'))\n",
    "X = text2vector(D)\n",
    "x=X['data']\n",
    "y=X['target']\n",
    "y2=(y >= 7) * 1.0\n",
    "ym=binClassify(X)\n",
    "print(\"Confusion matrix: \\n\" + str(confusion_matrix(y2, ym)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "## Classificador Multinomial <a name=\"multiclass\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após termos efetuado a vetorização do texto, e com a classificação binária tratada passamos para a classificação, em multiclass, dos dados usados. Foram escolhidos os mesmos três tipos de classificadores, elaboramos um método para cada classificador, para ficar a saber qual aquele que apresenta melhores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro classificador que decidimos estudar foi o *`logistic regression`*. Para isso criamos o método *`logistic_regression(Xtrain,Xtest,y1,y2, penaltyType = 'l1',cValue = None, solverType = 'liblinear', save_string=\"lr\")`* que recebe como argumentos os dados de treino e teste, ambos dividos pela vetorização, e passado como argumento o tipo de penalização que este classificador recebe(neste caso o lasso, ou seja 'l1', podendo ser alterado para ridge, ou seja 'l2'), o valor do coeficiente de correlação (neste caso ficou a None, visto que foi necessário para obter o melhor parâmetro), e o tipo de solver(que neste caso, obtamos por deixar como sendo 'liblinear').\n",
    "\n",
    "Para verificar qual o melhor parâmetro, criamos a condição *`if cValue is None`*. Caso esta condição seja verdadeira, verificamos o tipo de penalização para este classificador:\n",
    "\n",
    "* Caso o tipo de penalização seja lasso, ou seja, 'l1', criamos um dicionário de nome *`parametros`*, onde contém os diferentes valores do coeficiente de correlação, e os diferentes tipos de solvers que serão usados, e no final usamos o método *`logistic regression`* para aplicar consoante estes valores.\n",
    "* Caso o tipo de penalização seja ridge, ou seja, 'l2', criamos um dicionário de nome *`parametros`*, onde contém os diferentes valores do coeficiente de correlação, e os diferentes tipos de solvers que serão usados, e no final usamos o método *`logistic regression`* para aplicar consoante estes valores.\n",
    "* Sendo que estamos a estudar com um classificador multiclass, foi necessário passar o argumento *`multi_class='multinomial'`* quando é usado o método *`logistic regression`*, tendo a garantia que a classificação que obtemos no final, é em multiclass.\n",
    "* Ainda dentro da condição, caso não seja escolhido um valor do coeficiente de correlação, usamos o método *`GridSearchCV`* que permite obter o melhor parâmetro, passando este tipo de classificador.\n",
    "\n",
    "\n",
    "Caso a condição não seja verdadeira, aplicamos o método *`logistic regression`* consoante os valores que passamos nos argumentos no início deste método.\n",
    "\n",
    "No final é calculado o valor do score, tanto do treino como do teste, obtendo diferentes resultados, e tirar conclusões de qual o melhor solver e o melhor parâmetro a ser usado. Também optamos por imprimir a matriz de confusão, vendo quantos tipos de verdadeiros/falsos positivos/negativos podiamos obter. E no final, para testar que estamos a usar este classificador como sendo binário, imprimimos a matriz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Método que calcula regressão logística, consoante o tipo de penalização(lasso - l1 ou ridge - l2)\n",
    "e os diferentes tipos de solvers que existem\n",
    "\"\"\"\n",
    "\n",
    "def RegressaoLogistica(Xtrain,Xtest,y1,y2, penaltyType = 'l1',cValue = None, solverType = 'saga'):\n",
    "    \n",
    "    gs = None\n",
    "    tipoRegressao = \"Lasso\" if penaltyType == \"l1\" else \"Ridge\\n\" \n",
    "    gsMelhorParametro = None\n",
    "    print(\"Inicialização de Regressão Logistica \",tipoRegressao)\n",
    "    if cValue is None:\n",
    "        if penaltyType == \"l1\":\n",
    "            parametros = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "            lr = LogisticRegression(penalty=penaltyType,C= cValue,solver = solverType,max_iter=5000,\n",
    "                                    multi_class='multinomial')\n",
    "        elif penaltyType == \"l2\":\n",
    "            parametros={'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                        'solver' : ('saga','sag', 'lbfgs', 'newton-cg')\n",
    "                        }\n",
    "            lr = LogisticRegression(penalty = penaltyType,C= cValue,solver = solverType,max_iter = 5000,\n",
    "                                        multi_class='multinomial')\n",
    "        gs = GridSearchCV(lr, parametros)\n",
    "        gs.fit(Xtrain,y1)\n",
    "        gsMelhorParametro = gs.best_params_\n",
    "        print(\"O melhor parametro é: \", str(gsMelhorParametro))\n",
    "    else:\n",
    "        gs = LogisticRegression(penalty = penaltyType, solver = solverType, C = cValue, max_iter = 5000,multi_class='multinomial')\n",
    "        gs.fit(Xtrain,y1)\n",
    "    \n",
    "    save_data(gs,\"multi_lasso_porter\")\n",
    "    scoreTrain = np.round(gs.score(Xtrain, y1) * 100, 3)\n",
    "    scoreTest = np.round(gs.score(Xtest, y2) * 100, 3)\n",
    "    \n",
    "    print(\"Acertos no Treino: \" + str(scoreTrain))\n",
    "    print(\"Acertos no Teste: \" + str(scoreTest))\n",
    "    y2n = gs.predict(Xtest)\n",
    "    print(\"Matriz de Confusão: \\n\" + str(confusion_matrix(y2, y2n)))\n",
    "    print(\"As classes do Teste são: \" + str(y2n))\n",
    "    print(\"Regressão Logistica\",tipoRegressao,solverType, \"concluída\")\n",
    "    \n",
    "    return scoreTrain,scoreTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------LOGISTIC lasso - saga - 1---------------------------\n",
      "Multiclass classification\n",
      "Inicialização de Regressão Logistica  Lasso\n",
      "Writing data.\n",
      "Data written successfully\n",
      "Acertos no Treino: 47.643\n",
      "Acertos no Teste: 42.733\n",
      "Matriz de Confusão: \n",
      "[[2059   85   94  125   27   25    7  165]\n",
      " [ 642   73   99  137   30   35    4   84]\n",
      " [ 431   74  150  292   58   38   10  135]\n",
      " [ 307   53  136  384  105  106   19  153]\n",
      " [  73    9   29  115  253  238   48  325]\n",
      " [  81   12   25   69  204  293   54  632]\n",
      " [  50    3    8   44   84  146   46  675]\n",
      " [  96    5   17   37   74  166   77 1870]]\n",
      "As classes do Teste são: [ 4  7  1 ... 10  1  1]\n",
      "Regressão Logistica Lasso saga concluída\n",
      "Multiclass classification finished.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(47.643, 42.733)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"-----------------------LOGISTIC lasso - saga - 1---------------------------\")\n",
    "multi_classify(Xtrain2, Xtest2, ytrain, ytest,classifier_type = 'logistic lasso', cValue = 1, solverType = 'saga')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O segundo classificador que decidimos estudar foi o *`SVM, Máquina de Suporte Vetorial`*. Para isso criamos o método *`SVM(Xtrain, Xtest, y1, y2, cValue = None, kernelType = None, save_string=\"svm\")`* que recebe como argumentos os dados de treino e teste, ambos dividos pela vetorização, e passado como argumento o tipo de kernel que este classificador recebe o valor do coeficiente de correlação (neste caso ficou a None, visto que foi necessário para obter o melhor parâmetro).\n",
    "\n",
    "Para verificar qual o melhor parâmetro, criamos a condição *`if cValue is None and kernelType is None`*. Caso esta condição seja verdadeira, criamos um dicionário de nome *`parametros`*, onde contém os diferentes valores do coeficiente de correlação, e os diferentes tipos de kernels que serão usados, e no final usamos o método *`SVC`* para aplicar consoante estes valores. Ainda dentro da condição, caso não seja escolhido um valor do coeficiente de correlação, usamos o método *`GridSearchCV`* que permite obter o melhor parâmetro, passando este tipo de classificador.\n",
    "Para ter a garantia que este classificador retorna os resultados em multiclass, foi passado o argumento *`decision_function_shape='ovo'`*, ou seja, one-versus-one.\n",
    "\n",
    "Caso a condição não seja verdadeira, aplicamos o método *`SVC`* consoante os valores que passamos nos argumentos no início deste método.\n",
    "\n",
    "No final é calculado o valor do score, tanto do treino como do teste, obtendo diferentes resultados, e tirar conclusões de qual o melhor solver e o melhor parâmetro a ser usado. Também optamos por imprimir a matriz de confusão, vendo quantos tipos de verdadeiros/falsos positivos/negativos podiamos obter. E no final, para testar que estamos a usar este classificador como sendo binário, imprimimos a matriz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Método que calcula o SVM(máquina de suporta vetorial), passando um tipo de kernel\"\"\"\n",
    "def SVM(Xtrain, Xtest, y1, y2, cValue = None, kernelType = None):\n",
    "    \n",
    "    gs = None\n",
    "    print(\"Starting SVM\")\n",
    "    if cValue is None and kernelType is None:\n",
    "        parametros = {\n",
    "            'C': [0.001, 0.01, 0.1, 1, 10, 100], \n",
    "            'kernel' : ('linear', 'rbf', 'sigmoid')\n",
    "            }\n",
    "        svm = SVC(gamma = 'auto',max_iter=5000,decision_function_shape='ovo')\n",
    "        gs = GridSearchCV(svm, parametros)\n",
    "        gs.fit(Xtrain,y1)\n",
    "        print(\"O melhor parametro é: \", str(gs.best_params_))\n",
    "    else:\n",
    "        gs = SVC(gamma='auto', max_iter= 5000, decision_function_shape='ovo', C = cValue, kernel = kernelType)\n",
    "        gs.fit(Xtrain,y1)\n",
    "        \n",
    "    # save_data(gs,\"multi_svm_porter\")    \n",
    "    print(\"Train success: \" + str(np.round(gs.score(Xtrain, y1) * 100, 3)))\n",
    "    print(\"Test success: \" + str(np.round(gs.score(Xtest, y2) * 100, 3)))\n",
    "    y2n = gs.predict(Xtest)\n",
    "    print(\"Confusion matrix: \\n\" + str(confusion_matrix(y2, y2n)))\n",
    "    print(\"Test classes: \" + str(gs.predict(Xtest)))\n",
    "    print(\"SVM concluded\")\n",
    "    return np.round(gs.score(Xtrain, y1) * 100, 3), np.round(gs.score(Xtest, y2) * 100, 3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O terceiro e último classificador que decidimos estudar foi o *`kNN`*. Para isso criamos o método *`kNN(Xtrain, Xtest, y1, y2, n_neighborsValue = 5, save_string='knn')`* que recebe como argumentos os dados de treino e teste, ambos dividos pela vetorização, e passado como argumento a quantidade de vizinhos, neste caso, para teste, optamos por deixar com 5 vizinhos.\n",
    "\n",
    "Para verificar qual o melhor parâmetro, criamos a condição *`if n_neighborsValue == None`*. Caso esta condição seja verdadeira, criamos um dicionário de nome *`parameters`*, onde contém os diferentes valores de vizinhança. De seguida, usamos o método *`KNeighborsClassifier()`*. Ainda dentro desta condição, para obter o melhor parâmetro(neste caso, para este classificador, o melhor valor de vizinhança) \n",
    "Caso a condição não seja verdadeira, aplicamos o método *`SVC`* consoante os valores que passamos nos argumentos no início deste método.Usamos o método *`GridSearchCV`* que permite obter o melhor parâmetro, passando este tipo de classificador.\n",
    "\n",
    "No final é calculado o valor do score, tanto do treino como do teste, obtendo diferentes resultados, e tirar conclusões de qual o melhor melhor vizinho a ser usado. Também optamos por imprimir a matriz de confusão, vendo quantos tipos de verdadeiros/falsos positivos/negativos podiamos obter. E no final, para testar que estamos a usar este classificador como sendo binário, imprimimos a matriz de teste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Método que calcula a vizinhança knn, passando como argumento o número de vizinhos\"\"\"\n",
    "def kNN(Xtrain,Xtest,y1,y2,n_neighborsValue = 5):\n",
    "    \n",
    "    gs = None\n",
    "    print(\"kNN started.\")\n",
    "    if n_neighborsValue == None:\n",
    "        parameters = {\n",
    "                    'n_neighbors': [ 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, \n",
    "                                    100, 105, 110, 115, 120, 125, 130, 135, 140, 145, 150, 155, 160, 165, 170, 175, 180, 185, 190, 195, \n",
    "                                    200, 205, 210, 215, 220, 225, 230, 235, 240, 245, 250, 255, 260, 265, 270, 275, 280, 285, 290, 295, \n",
    "                                    300, 305, 310, 315, 320, 325, 330, 335, 340, 345, 350, 355, 360, 365, 370, 375, 380, 385, 390, 395, \n",
    "                                    400, 405, 410, 415, 420, 425, 430, 435, 440, 445, 450, 455, 460, 465, 470, 475, 480, 485, 490, 495] \n",
    "    \n",
    "                    }\n",
    "        knn = KNeighborsClassifier()\n",
    "        gs = GridSearchCV(knn, parameters)\n",
    "        gs.fit(Xtrain,y1)\n",
    "    else: \n",
    "        gs = KNeighborsClassifier(n_neighbors = n_neighborsValue)\n",
    "        gs.fit(Xtrain,y1)\n",
    "    \n",
    "    # save_data(gs,\"multi_knn_porter\")\n",
    "    print(\"Train success: \" + str(np.round(gs.score(Xtrain, y1) * 100, 3)))\n",
    "    print(\"Test success: \" + str(np.round(gs.score(Xtest, y2) * 100, 3)))\n",
    "    y2n = gs.predict(Xtest)\n",
    "    print(\"Confusion matrix: \\n\" + str(confusion_matrix(y2, y2n)))\n",
    "    print(\"Test classes: \" + str(gs.predict(Xtest)))\n",
    "    print(\"kNN Classifier concluded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar a parte que diz respeito à classificação binária, foi realizado o método *`multi_classify(Xtrain,Xtest,y1,y2,classifier_type = 'logistic lasso', cValue = None, solverType = None, kernelType = None):`*. Dentro deste método, criamos diferentes condições para verificar qual o tipo de classificador que queremos correr. Ao ser chamado este método, sempre que o tipo de classificador seja \"logistic lasso\", irá ser corrido o método que foi criado para a regressão logísica, neste caso, para o lasso. O procedimento para correr os outros classificadores é idêntico. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Método que retorna os resultados do treino e do teste, consoante a classificação (em multiclass) escolhida\"\"\"\n",
    "def multi_classify(Xtrain,Xtest,y1,y2,\n",
    "                classifier_type = 'logistic lasso', \n",
    "                cValue = None, \n",
    "                solverType = None, \n",
    "                kernelType = None):\n",
    "    \n",
    "\n",
    "    print(\"Multiclass classification\")    \n",
    "    classifier_type = classifier_type.lower()\n",
    "    result = 0\n",
    "    \n",
    "    if classifier_type == 'logistic lasso': result = RegressaoLogistica(Xtrain, Xtest, y1, y2,'l1', cValue, solverType)\n",
    "    if classifier_type == 'logistic ridge': result = RegressaoLogistica(Xtrain, Xtest, y1, y2,'l2', cValue, solverType)\n",
    "    if classifier_type == 'svm': resultado = SVM(Xtrain, Xtest, y1, y2,cValue, kernelType)\n",
    "    if classifier_type == 'knn': resultado = kNN(Xtrain, Xtest, y1, y2, solverType)\n",
    "\n",
    "    print(\"Multiclass classification finished.\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "O método *`multiClassify`* recebe o dicionário com os dados vetorizados resultante da aplicação do método *`text2vector`*.\n",
    "Neste método é evocado o método *`unpack`* para obter os dados e as classes a que estes dados pertencem. Seguidamente é obtido o classificador multiclasse previamente treinado que obteve melhores resultados, o regressor logístico com o classificador ridge, e é realizado o *`predict`* sobre os dados que são fornecidos. Por fim é retornado um array com o resultado deste *`predict`*, sendo que desta feita o array é composto por valores de 1 a 4 e de 7 a 10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Método que classifica o ficheiro, em multiclass, com o melhor classificador escolhido\"\"\"\n",
    "def multiClassify(X):\n",
    "    \n",
    "    x, y = unpack(X)\n",
    "    fName= \"multi_ridge_porter.p\"\n",
    "    D = pickle.load(open(fName, 'rb'))\n",
    "    gs = D['data']\n",
    "    yMulti = gs.predict(x)\n",
    "    return yMulti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start text clearing\n",
      "Text clearing finished\n",
      "Start stemming:  Porter Stemmer\n",
      "\n",
      "Stemming finished.\n",
      "\n",
      "Confusion matrix: \n",
      "[[7755   55   94  156   19   35    7  231]\n",
      " [1677 1342  124  254   35   53    8  197]\n",
      " [1154   53 1885  383   78   69   11  290]\n",
      " [ 758   36  154 2711  132  105   21  328]\n",
      " [ 174    7   49  156 2136  297   36  889]\n",
      " [ 176    9   25   96  227 2508   51 1437]\n",
      " [ 121    6   20   55  136  291 1227 1756]\n",
      " [ 181    9   12   53  122  212   45 7271]]\n"
     ]
    }
   ],
   "source": [
    "D=pickle.load(open('imdbFullPorter.p','rb'))\n",
    "X = text2vector(D)\n",
    "x=X['data']\n",
    "y=X['target']\n",
    "ym=multiClassify(X)\n",
    "print(\"Confusion matrix: \\n\" + str(confusion_matrix(y, ym)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "## Regressão Linear <a name=\"linear\"/>\n",
    "\n",
    "Um dos tópicos escolhis foi a regressão linear. O objetivo deste tipo de regressão consiste em  treinar e avaliar um modelo de regressão linear e comparar os resultados obtidos no problema de classificação multi-classe, com os da classificação binária.\n",
    "\n",
    "Este tipo de regressão linear consiste numa equação para se estimar a condicional (valor esperado) de uma variável y, dados os valores de algumas outras variáveis x.\n",
    "\n",
    "A regressão linear é chamada \"linear\" porque se considera que a relação da resposta às variáveis é uma função linear de alguns parâmetros. Os modelos de regressão que não são uma função linear dos parâmetros se chamam modelos de regressão não-linear.\n",
    "\n",
    "Como sempre, importamos as bibliotecas necessárias para a realização dos métodos acerca deste tópico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro método que decidimos criar foi o *`RegressaoLinear(Xtrain,Xtest,y1,y2)`* que recebe como argumentos os dados de treino e teste, ambos dividos pela vetorização.\n",
    "\n",
    "Este método apenas calcula a regressão linear, chamando o método *`LinearRegression`*, que permite calcular a regressão linear, passando os dados de treino.\n",
    "\n",
    "No final é calculado o valor do coeficiente R2, tanto do treino como do teste, obtendo diferentes resultados, e tirar conclusões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Método que calcula a regressão linear\"\"\"\n",
    "def RegressaoLinear(Xtrain,Xtest,y1,y2):\n",
    "    \n",
    "    print(\"Inicio da regressão linear \\n\")\n",
    "    lr = LinearRegression().fit(Xtrain,y1)\n",
    "    scoreTrain = np.round(lr.score(Xtrain,y1),2)\n",
    "    scoreTest = np.round(lr.score(Xtest,y2),2)\n",
    "    print(\"Resultado do coeficiente R2 da classe Treino: \",str(scoreTrain))\n",
    "    print(\"Resultado do coeficiente R2 da classe Treino: \",str(scoreTest))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De seguida, prodecemos à regressão linear, no que diz respeito ao lasso(visto que é necessário era necessário testar os dados com um modelo de regressão linear). Para isso criamos o método *`RegressaoLinearLasso(Xtrain,Xtest,y1,y2,alpha = None)`* que recebe como argumentos os dados de treino e teste, ambos dividos pela vetorização, e um valor de alpha, usando os mesmo valores que foram passados como coeficente de correlação nos classificadores anteriores.\n",
    "\n",
    "Para verificar qual o melhor valor do alpha, criamos a condição *`if alpha is None`*. Caso esta condição seja verdadeira, criamos um dicionário, de nome *`parametros`* que contém os mesmos valores que foram passados nos classificadores passados. De seguida usamos o método *`Lasso()`* para aplicar a regressão linear, consoante o classificador usado, e no final, usar o método *`GridSearchCV`* para determinar qual o melhor parâmetro, neste caso, o melhor *`alpha`*.\n",
    "\n",
    "Caso a condição não seja verdadeira, aplicamos o método *`Lasso`* consoante os valores que passamos nos argumentos no início deste método.\n",
    "\n",
    "No final é calculado o valor do coeficiente R2, tanto do treino como do teste, obtendo diferentes resultados, e tirar conclusões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Método que calcula a regressao linear com Lasso\"\"\"\n",
    "def RegressaoLinearLasso(Xtrain,Xtest,y1,y2,alpha = None):\n",
    "    \n",
    "    gs = None\n",
    "    print(\"Inicio do Lasso \\n\")\n",
    "    if alpha is None:\n",
    "        print(\"Yay entrei no none\")\n",
    "        parametros = {'alpha':[0.001,0.01,0.1,1,10,10,1000]}\n",
    "        lasso = Lasso(max_iter=5000)\n",
    "        gs = GridSearchCV(lasso,parametros).fit(Xtrain,y1)\n",
    "        print(\"Melhor parametro: \" + str(gs.best_params_))\n",
    "    else:\n",
    "        gs = Lasso(alpha,max_iter=5000).fit(Xtrain,y1)\n",
    "    \n",
    "    scoreTreino = np.round(gs.score(Xtrain,y1),2)\n",
    "    scoreTeste = np.round(gs.score(Xtest,y2),2)\n",
    "    \n",
    "    print(\"Resultado do coeficiente R2 da classe Treino: \",scoreTreino)\n",
    "    print(\"Resultado do coeficiente R2 da classe Teste: \",scoreTeste)\n",
    "    \n",
    "    return scoreTreino,scoreTeste\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De seguida, efetuamos o mesmo tipo de regressão linear, mas neste caso, fomos calcular para o método*`Ridge`*. Para isso criamos o método *`RegressaoLinearRidge(Xtrain,Xtest,y1,y2,alpha = None)`* que recebe como argumentos os dados de treino e teste, ambos dividos pela vetorização, e um valor de alpha, usando os mesmo valores que foram passados como coeficente de correlação nos classificadores anteriores.\n",
    "\n",
    "Para verificar qual o melhor valor do alpha, criamos a condição *`if alpha is None`*. Caso esta condição seja verdadeira, criamos um dicionário, de nome *`parametros`* que contém os mesmos valores que foram passados nos classificadores passados. De seguida usamos o método *`Ridge()`* para aplicar a regressão linear, consoante o classificador usado, e no final, usar o método *`GridSearchCV`* para determinar qual o melhor parâmetro, neste caso, o melhor *`alpha`*.\n",
    "\n",
    "Caso a condição não seja verdadeira, aplicamos o método *`Ridge`* consoante os valores que passamos nos argumentos no início deste método.\n",
    "\n",
    "No final é calculado o valor do coeficiente R2, tanto do treino como do teste, obtendo diferentes resultados, e tirar conclusões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Método que calcula a regressao linear com Ridge\"\"\"\n",
    "def RegressaoLinearRidge(Xtrain,Xtest,y1,y2,alpha = None):\n",
    "    \n",
    "    gs = None\n",
    "    print(\"Inicio do Ridge \\n\")\n",
    "    \n",
    "    if alpha is None:\n",
    "        parametros = {'alpha':[0.001,0.01,0.1,1,10,10,1000]}\n",
    "        ridge = Ridge(max_iter=5000)\n",
    "        gs = GridSearchCV(ridge,parametros).fit(Xtrain,y1)\n",
    "        print(\"Melhor parametro: \" + str(gs.best_params_))\n",
    "    else:\n",
    "        gs = Ridge(alpha,max_iter=5000).fit(Xtrain,y1)\n",
    "    \n",
    "    scoreTreino = np.round(gs.score(Xtrain,y1),2)\n",
    "    scoreTeste = np.round(gs.score(Xtest,y2),2)\n",
    "    \n",
    "    print(\"Resultado do coeficiente R2 da classe Treino: \",scoreTreino)\n",
    "    print(\"Resultado do coeficiente R2 da classe Teste: \",scoreTeste)\n",
    "    \n",
    "    return scoreTreino,scoreTeste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De seguida, efetuamos regressão linear, mas para um modelo não linear. Para isso criamos o método *`MaquinaSuporteVetorialLinear(Xtrain,Xtest,y1,y2,cValue = None,kernelType = 'rbf')`* que recebe como argumentos os dados de treino e teste, ambos dividos pela vetorização, e passado como argumento o tipo de kernel que este classificador recebe o valor do coeficiente de correlação (neste caso ficou a None, visto que foi necessário para obter o melhor parâmetro).\n",
    "\n",
    "Para verificar qual o melhor parâmetro, criamos a condição *`if cValue is None and kernelType is None`*. Caso esta condição seja verdadeira, criamos um dicionário de nome *`parametros`*, onde contém os diferentes valores do coeficiente de correlação, e os diferentes tipos de kernels que serão usados, e no final usamos o método *`SVC`* para aplicar consoante estes valores. Ainda dentro da condição, caso não seja escolhido um valor do coeficiente de correlação, usamos o método *`GridSearchCV`* que permite obter o melhor parâmetro, passando este tipo de classificador.\n",
    "\n",
    "Caso a condição não seja verdadeira, aplicamos o método *`SVC`* consoante os valores que passamos nos argumentos no início deste método.\n",
    "\n",
    "No final é calculado o valor do score, tanto do treino como do teste, obtendo diferentes resultados, e tirar conclusões de qual o melhor solver e o melhor parâmetro a ser usado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Método que calcula o SVR\"\"\"\n",
    "def MaquinaSuporteVetorialLinear(Xtrain,Xtest,y1,y2,cValue = None,kernelType = 'rbf'):\n",
    "    \n",
    "    gs = None\n",
    "    print(\"Inicio do SVR \\n\")\n",
    "    if cValue == None and kernelType == None:\n",
    "        parametros = {\n",
    "            'C': [0.001, 0.01, 0.1, 1, 10, 100], \n",
    "            'kernel' : ('linear', 'rbf', 'poly')\n",
    "            }\n",
    "        svr = SVR(gamma = 'auto',max_iter=-1)\n",
    "        gs = GridSearchCV(svr,parametros).fit(Xtrain,y1)\n",
    "        print(\"Melhor parametro: \" + str(gs.best_params_))\n",
    "    else:\n",
    "        gs = SVR(gamma = 'auto',max_iter=-1, C = cValue,kernel = kernelType).fit(Xtrain,y1)\n",
    "    scoreTreino = np.round(gs.score(Xtrain,y1),2)\n",
    "    scoreTeste = np.round(gs.score(Xtest,y2),2)\n",
    "    \n",
    "    print(\"Resultado do coeficiente R2 da classe Treino: \",scoreTreino)\n",
    "    print(\"Resultado do coeficiente R2 da classe Teste: \",scoreTeste)\n",
    "    \n",
    "    return scoreTreino,scoreTeste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar a parte que diz respeito à regressão linear, foi realizado o método *`classificadorRegressao(Xtrain,Xtest,y1,y2,binario = True, tipoClassificador = \"regressao linear\",alpha = None,\n",
    " cValue = None,kernelType = 'rbf')`*. Dentro deste método, criamos diferentes condições para verificar qual o tipo de classificador que queremos correr. Passando um valor booleano como argumento deste método,caso seja *`True`*, ele efetua uma classificação de regressão linear como sendo binária, mas caso essa condição seja *`False`*, ele executa o método como sendo uma regressão linear em multiclass. Ao ser chamado este método, sempre que o tipo de classificador seja \"regressao linear\", irá ser corrido o método que foi criado para a regressão logísica, neste caso, para o lasso. O procedimento para correr os outros classificadores é idêntico. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Método que retorna os resulados do treino e do teste, consoante a classificação escolhida\"\"\"\n",
    "def classificadorRegressao(Xtrain,Xtest,y1,y2,binario = True, \n",
    "                           tipoClassificador = \"regressao linear\",\n",
    "                           alpha = None,\n",
    "                           cValue = None,\n",
    "                           kernelType = 'rbf'):\n",
    "    \n",
    "    if binario:\n",
    "        y1 = (y1 >= 7) * 1.0\n",
    "        y2 = (y2 >= 7) * 1.0\n",
    "        \n",
    "    tipoClassificador = tipoClassificador.lower()\n",
    "    resultado = 0\n",
    "    \n",
    "    if tipoClassificador == 'regressao linear': resultado = RegressaoLinear(Xtrain, Xtest, y1, y2)\n",
    "    elif tipoClassificador == 'regressao ridge': resultado = RegressaoLinearRidge(Xtrain, Xtest, y1, y2,alpha)\n",
    "    elif tipoClassificador == 'regressao lasso': resultado = RegressaoLinearLasso(Xtrain, Xtest, y1, y2,alpha)\n",
    "    elif tipoClassificador == 'svr': resultado = MaquinaSuporteVetorialLinear(Xtrain, Xtest, y1, y2, cValue,kernelType)\n",
    "    print(\"Fim da classificação Regressao Linear \\n\")\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fN = 'imdbFullPorter.p'\n",
    "\n",
    "D = pickle.load(open(fN,'rb')) \n",
    "D.keys() \n",
    "dados = D['data']\n",
    "target = D['target']\n",
    "\n",
    "X1, X2, y1, y2 = train_test_split(dados,target,test_size=0.3,random_state = 42)\n",
    "x_train, x_test, ytrain, ytest , voc2 = text_to_vector(X1, X2, y1, y2, n_grams = (1,3))\n",
    "#----------------------------Regressao Linear---------------------\n",
    "#print(\"-----------------------Regressao Linear(bin)--------------------------\")\n",
    "#classificadorRegressao(x_train,x_test,y1,y2,binario= True, tipoClassificador = 'regressao linear',alpha = None)\n",
    "#print()\n",
    "#print(\"-----------------------Regressao Linear-Lasso(bin)--------------------------\")\n",
    "#classificadorRegressao(x_train,x_test,y1,y2,binario= True, tipoClassificador = 'regressao lasso',alpha = None)\n",
    "#print()\n",
    "#print(\"-----------------------Regressao Linear-ridge(bin)--------------------------\")\n",
    "#classificadorRegressao(x_train,x_test,y1,y2,binario= True, tipoClassificador = 'regressao ridge',alpha = None)\n",
    "#print()\n",
    "#print(\"-----------------------Regressao Linear-svr(bin)--------------------------\")\n",
    "#classificadorRegressao(x_train,x_test,y1,y2,binario= True, tipoClassificador = 'svr',cValue = None, kernelType=None)\n",
    "\n",
    "\n",
    "#print(\"-----------------------Regressao Linear--------------------------\")\n",
    "#classificadorRegressao(x_train,x_test,y1,y2,binario= False, tipoClassificador = 'regressao linear',alpha = None)\n",
    "#print()\n",
    "#print(\"-----------------------Regressao Linear-Lasso(--------------------------\")\n",
    "#classificadorRegressao(x_train,x_test,y1,y2,binario= False, tipoClassificador = 'regressao lasso',alpha = None)\n",
    "#print()\n",
    "#print(\"-----------------------Regressao Linear-ridge--------------------------\")\n",
    "#classificadorRegressao(x_train,x_test,y1,y2,binario= False, tipoClassificador = 'regressao ridge',alpha = None)\n",
    "#print()\n",
    "#print(\"-----------------------Regressao Linear-svr--------------------------\")\n",
    "#classificadorRegressao(x_train,x_test,y1,y2,binario= False, tipoClassificador = 'svr',cValue = None, kernelType='None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poupar tempo de processamento, decidimos apresentar os resultados nas figuras a seguir, no que diz respeito à regressão linear. Depois de ser feita a classificação para a regressão linear, os resultados obtidos podem ser encontrados nas figuras a seguir. A figura à esquerda permite obter os resultados, quando passado pela regressão linear, mas em binário. Já a figura na direita, foram os resultados obtidos da regressão linear, mas em multiclass.\n",
    "\n",
    "\n",
    "<img src=\"https://i.imgur.com/2lizGn1.png\" width=\"400\" height=\"400\" style=\"float:left\">\n",
    "<img src=\"https://i.imgur.com/D1sZu7J.png\" width=\"400\" height=\"400\" style=\"float:right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/sh4w9d6.png\" width=\"400\" height=\"400\" style=\"float:left\">\n",
    "<img src=\"https://i.imgur.com/0LhRP0P.png\" width=\"400\" height=\"400\" style=\"float:right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se pode observar, nas figuras acima, conseguimos obter o melhor parâmetro alpha, assim como os resultados do treino e do teste. Analisando as imagens, podemos reparar que, comparando os dois tipos de classificadores, os resultados foram idênticos. A única diferença é que o classificador que não está a ser como binário, na regressão linear, lasso, apresenta melhores resultados que o binário. O mesmo se pode dizer o SVR, pois apresenta uma percentagem superior, ao contrário do binário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "## Dimensão do Vocabulário<a name=\"dimensao\"/>\n",
    "\n",
    "O outro tópico escolhido foi a dimensão do vocabulário. O objetivo deste tópico é investigar a influência do tamanho do dicionário(dimensão dos dados) no desempenho de um discriminante logístico no problema de classificação binária.  \n",
    "Começamos por construir um dicionário(neste caso com 30000 dimensões) aplicando stemming(neste caso, iremos usar mais uma ver, o stemm Porter) e usada a regularização lasso. Para tirar breves conclusões deste tópico, iremos reduzir o tamanho do nosso dicionário, e ver até onde ele consegue processar os dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi criado o método *`LassoRegression(Xtrain,Xtest,y1,y2,penaltyType = \"l1\",cValue = None)`* que recebe como argumentos os dados de treino e teste, ambos dividos pela vetorização, o tipo de penalização (neste caso, lasso) e um valor do coeficiente de correlação). \n",
    "\n",
    "Dentro deste método, recorremos ao tipo de solver \"saga\", visto que como tamos a tratar de muitos dados, é o melhor que consegue lidar com uma grande quantidade de dados processados.\n",
    "\n",
    "De seguida, guardamos os valores dos coeficiente, e efetuamos um sort desses coeficientes, usando o método *`np.argsort`*. No final deste método, é feito prints, do número de erros, através da expressão *`np.sum(w!=0)`* , e feito também, o print da matriz de confusão e os acertos de treino e de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Método que calcula a regressão, em lasso\"\"\"\n",
    "def LassoRegression(Xtrain,Xtest,y1,y2,penaltyType = \"l1\",cValue = None):\n",
    "    \n",
    "    lr = LogisticRegression(penalty = \"l1\",solver = 'saga', C = cValue).fit(Xtrain,y1)\n",
    "    w =lr.coef_\n",
    "    idx = np.argsort(w)\n",
    "    w = w.squeeze()\n",
    "    idx = idx.ravel()\n",
    "    scoreTrain = np.round(lr.score(Xtrain, y1) * 100, 3)\n",
    "    scoreTest = np.round(lr.score(Xtest, y2) * 100, 3)\n",
    "    print(\"Número de Erros: \", np.sum(w!=0))\n",
    "    print(\"Número de Acertos: \", np.sum(w==0))\n",
    "    print(\"Acertos no Treino: \" + str(scoreTrain))\n",
    "    print(\"Acertos no Teste: \" + str(scoreTest))\n",
    "    y2n = lr.predict(Xtest)\n",
    "    print(\"Matriz de Confusão: \\n\" + str(confusion_matrix(y2, y2n)))\n",
    "    print(\"Fim de regularização Lasso\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi reaproveitado o rocedemos à realização da divisão do ficheiro, em treino e teste. *`text2Vector(Xtrain,Xtest,n_grams = (2,2),max_featuresV = None)`*, recebendo como argumentos os dados de treino e de teste, passando bigramas (n-gramas de (2,2)), e o max_featuresV.\n",
    "\n",
    "Recorremos ao método *`TfidfVectorizer`* para aplicar esse conjunto de dados, numa matriz tfidf, passando os n-gramas e o número máximo de features (*`max_featuresV`*).\n",
    "\n",
    "No final, aplicamos esta transformação, tantos para os dados de treino, como para os dados de teste. No final, retornamos os dados de teste e de treino convertidos, assim como um vocabulário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Método que converte um documento, em texto, para uma matriz de vetores(X)\"\n",
    "def text2Vector(Xtrain,Xtest,n_grams = (1,3),max_featuresV = None):\n",
    "    \n",
    "    print(\"Inicialização de converção de texto para vectores.\\n\")\n",
    "    tfidf = TfidfVectorizer(ngram_range = n_grams,max_features = max_featuresV).fit(Xtrain)\n",
    "    voc = tfidf.get_feature_names()\n",
    "    Xtrain = tfidf.transform(Xtrain)\n",
    "    Xtest = tfidf.transform(Xtest)\n",
    "    return Xtrain,Xtest,voc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para terminar a realização deste tópico, realizamos o método *`classify(Xtrain,Xtest,y1,y2,penaltyType=\"l1\",cValue = None)`*. Dentro deste método, fazemos a conversão dos dados para binário, através da seguinte condição:*` y1 = (y1 >= 7) * 1.0`* e *` y2 = (y2 >= 7) * 1.0`*, e chamamos o método criado no início deste tópico, passando os dados de treino e de teste, assim como o tipo de classificador usado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Método que retorna uma classificação, em binário\"\"\"\n",
    "def classify(Xtrain,Xtest,y1,y2,penaltyType=\"l1\",cValue = None):\n",
    "    \n",
    "    print(\"Inicialização de classificação\\n\")\n",
    "    y1 = (y1 >= 7) * 1.0\n",
    "    y2 = (y2 >= 7) * 1.0\n",
    "    \n",
    "    LassoRegression(Xtrain,Xtest,y1,y2,'l1',cValue)\n",
    "    print(\"End of the classify\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fN = 'imdbFullPorter.p'\n",
    "D = pickle.load(open(fN,'rb')) \n",
    "D.keys() \n",
    "dados = D['data']\n",
    "target = D['target']\n",
    "X1, X2, y1, y2 = train_test_split(dados,target,test_size=0.3,random_state = 42)\n",
    "x_train, x_test, Vocab = text2Vector(X1, X2,max_featuresV = 150)\n",
    "classify(x_train, x_test, y1, y2, penaltyType = 'l1', cValue = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poupar tempo de processamento, decidimos apresentar os resultados nas figuras a seguir, no que diz respeito aos diferentes valores da dimensão do vocabulário.\n",
    "\n",
    "Na figura à esquerda, os resultados apresentados, são corridos com 30000 dados. Já na figura a seguir, reduzimos os dados para metade, ou seja, 15000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/5DxvTdX.png\" width=\"400\" height=\"400\" style=\"float:left\">\n",
    "<img src=\"https://i.imgur.com/NGZLC1v.png\" width=\"400\" height=\"400\" style=\"float:right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na figura à esquerda, os resultados apresentados, são corridos com 5000 dados. Já na figura a seguir, reduzimos os dados para metade, ou seja, 50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/E9Auwym.png\" width=\"400\" height=\"400\" style=\"float:left\">\n",
    "<img src=\"https://i.imgur.com/0PQOoTG.png\" width=\"400\" height=\"400\" style=\"float:right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, chega-se ao limite dos dados que consegue processar, ou seja, apenas consegue correr até 5 dados. Abaixo disto, apresenta erros, não mostrando resultados. Na figura a seguir, podemos ver os resultados obtidos, com apenas 5 dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/ObxZyMY.png\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "## TESTES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classificadoresBin = ['logistic lasso','logistic ridge','svm','knn']\n",
    "c_value = [.001, .01, .1, 1, 10]\n",
    "for i in range(len(c_value)):\n",
    "    bin_classify(Xtrain2, Xtest2, ytrain, ytest,classificadoresBin[0],cValue[i], solverType = 'liblinear')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classificadoresBin = ['logistic lasso','logistic ridge','svm','knn']\n",
    "# =============================================================================\n",
    "# print(\"-----------------------LOGISTIC lasso - liblinear---------------------------\")\n",
    "# binClassify(x_train, x_test, y1, y2,classificadoresBin[0],cValue = 1, solverType = 'liblinear')\n",
    "# print()\n",
    "# print(\"-----------------------LOGISTIC lasso - saga---------------------------\")\n",
    "# binClassify(x_train, x_test, y1, y2,classificadoresBin[0],cValue = 1, solverType = 'saga')\n",
    "# print()\n",
    "# print(\"-----------------------LOGISTIC ridge - lbfgs---------------------------\")\n",
    "# binClassify(x_train, x_test, y1, y2,classificadoresBin[1], cValue = 10, solverType = 'lbfgs')\n",
    "# print()\n",
    "# print(\"-----------------------LOGISTIC ridge - saga---------------------------\")\n",
    "# binClassify(x_train, x_test, y1, y2,classificadoresBin[1], cValue = 10, solverType = 'saga')\n",
    "# print()\n",
    "# print(\"-----------------------LOGISTIC ridge - sag---------------------------\")\n",
    "# binClassify(x_train, x_test, y1, y2,classificadoresBin[1], cValue = 10, solverType = 'sag')\n",
    "# print()\n",
    "# print(\"-----------------------LOGISTIC ridge - newton-cg---------------------------\")\n",
    "# binClassify(x_train, x_test, y1, y2,classificadoresBin[1], cValue = 10, solverType = 'newton-cg')\n",
    "# print(\"-----------------------SVM - linear---------------------------\")\n",
    "# binClassify(x_train, x_test, y1, y2,classificadoresBin[2], cValue = 1, kernelType = 'linear')\n",
    "# print()\n",
    "# print(\"-----------------------SVM - linear---------------------------\")\n",
    "# binClassify(x_train, x_test, y1, y2,classificadoresBin[2], cValue = 1, kernelType = 'linear')\n",
    "#print()\n",
    "#print(\"-----------------------SVM - rbf---------------------------\")\n",
    "#binClassify(x_train, x_test, y1, y2,classificadoresBin[2], cValue = 1, kernelType = 'rbf')\n",
    "# print()\n",
    "#print(\"-----------------------SVM - sigmoid---------------------------\")\n",
    "#binClassify(x_train, x_test, y1, y2,classificadoresBin[2], cValue = 1, kernelType = 'sigmoid')\n",
    "#print(\"-----------------------knn---------------------------\")\n",
    "#binClassify(x_train, x_test, y1, y2,classificadoresBin[3], n_neighborsValue = 200)\n",
    "\n",
    "\n",
    "#classificadoresMulti = ['logistic lasso','logistic ridge','svm','knn']\n",
    "#----------------------------MULTICLASSE---------------------\n",
    "#print(\"-----------------------LOGISTIC lasso - saga---------------------------\")\n",
    "#multiClassify(x_train, x_test, y1, y2,classificadoresMulti[0],cValue = 1, solverType = 'saga')\n",
    "#print()\n",
    "#print(\"-----------------------LOGISTIC ridge - lbfgs---------------------------\")\n",
    "#multiClassify(x_train, x_test, y1, y2,classificadoresMulti[1], cValue = 10, solverType = 'lbfgs')\n",
    "#print()\n",
    "#print(\"-----------------------LOGISTIC ridge - saga---------------------------\")\n",
    "#multiClassify(x_train, x_test, y1, y2,classificadoresMulti[1], cValue = 10, solverType = 'saga')\n",
    "#print()\n",
    "#print(\"-----------------------LOGISTIC ridge - sag---------------------------\")\n",
    "#multiClassify(x_train, x_test, y1, y2,classificadoresMulti[1], cValue = 10, solverType = 'sag')\n",
    "#print()\n",
    "#print(\"-----------------------LOGISTIC ridge - newton-cg---------------------------\")\n",
    "#multiClassify(x_train, x_test, y1, y2,classificadoresMulti[1], cValue = 10, solverType = 'newton-cg')\n",
    "#print(\"-----------------------SVM - linear---------------------------\")\n",
    "#multiClassify(x_train, x_test, y1, y2,classificadoresMulti[2], cValue = 1, kernelType = 'linear')\n",
    "#print(\"-----------------------SVM - rbf---------------------------\")\n",
    "#multiClassify(x_train, x_test, y1, y2,classificadoresMulti[2], cValue = 1, kernelType = 'rbf')\n",
    "#print()\n",
    "#print(\"-----------------------SVM - sigmoid---------------------------\")\n",
    "#multiClassify(x_train, x_test, y1, y2,classificadoresMulti[2], cValue = 1, kernelType = 'sigmoid')\n",
    "#print(\"-----------------------knn---------------------------\")\n",
    "#binClassify(x_train, x_test, y1, y2,classificadoresMulti[3], n_neighborsValue = 200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "## Conclusões<a name=\"conclusao\"/>\n",
    "\n",
    "Com a realização deste trabalho, conseguimos entender melhor como usufruir dos diferentes classificadores binários e multiclasse que as bibliotecas python fornecem, e obter diferentes resultados consoante os diferentes classificadores utilizados.\n",
    "\n",
    "O grupo concretizou a maioria dos objetivos propostos no enunciado, o que facilitou a\n",
    "aprendizagem acerca desta matéria. Inicialmente foram criados métodos para fazer a conversão do texto para vetores, ponto fulcral para o funcionamento dos classificadores utilizados.\n",
    "\n",
    "Deste modo, os objetivos foram alcançados dentro dos nossos conhecimentos, mas ao longo da realização do trabalho, o grupo deparou-se com problemas, nomeadamente o tempo de processamento que cada classificador consome. Não foi possível realizar todos os testes necessários para obter algumas das comparações dos resultados que pretendia obter, sendo que apenas foram realizados testes para a maioria dos valores aqui apresentados.\n",
    "\n",
    "Apesar das dificuldades encontradas, foram adquiridos conhecimentos acerca de toda a matéria lecionada, levando mais conhecimentos acerca dos diferentes classificadores, e a função que cada um tem bem como a utilidade da aplicação dos mesmos como métodos de classificação de dados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "## Bibliografia<a name=\"bibliografia\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Folhas fornecidas pelo docente da disciplina;\n",
    "* Documentação python:\n",
    "    * Sklearn: https://scikit-learn.org/stable/ ; \n",
    "    * Nltk: https://www.nltk.org/ ;\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
